<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>Seeing Beneath Dense Forest Canopies</title>
    <meta
      name="description"
      content="WACV 2026 Workshop (CV4EO) paper on under-canopy terrain reconstruction in dense forests using RGB imaging and neural 3D reconstruction."
    />
    <meta
      property="og:title"
      content="Seeing Beneath Dense Forest Canopies"
    />
    <meta
      property="og:description"
      content="WACV 2026 Workshop (CV4EO) paper on under-canopy terrain reconstruction in dense forests using RGB imaging and neural 3D reconstruction."
    />
    <meta property="og:type" content="website" />
    <meta property="og:image" content="assets/img/forestvisionlab-logo.png" />
    <link rel="stylesheet" href="assets/css/style.css" />
  </head>
  <body>
    <header class="hero">
      <div class="hero-content">
        <div class="hero-text">
          <div class="hero-top">
            <a
              class="venue"
              id="venue"
              href="https://geoai.ornl.gov/cv4eo-wacv/?fireglass_rsn=true#fireglass_params&tabid=aea62bb3771a5188&start_with_session_counter=3&application_server_address=wiweb-11-me-west1.prod.fire.glass"
              target="_blank"
              rel="noopener noreferrer"
            >
              WACV 2026 Workshop (CV4EO)
            </a>
            <div class="hero-logos" id="logos" aria-label="Workshop and lab logos"></div>
          </div>
          <h1 id="title">Seeing Beneath Dense Forest Canopies</h1>
          <p class="subtitle" id="subtitle">
            Under-Canopy Terrain Reconstruction in Dense Forests Using RGB Imaging and Neural 3D Reconstruction
          </p>
          <div class="authors hero-authors" id="hero-authors" aria-label="Authors"></div>
          <p class="hero-micro-abstract">
            Dense forest canopies obscure ground visibility, limiting mapping and search-and-rescue capabilities.
          </p>
          <div class="quick-links" id="quick-links"></div>
        </div>
        <div class="hero-demo" id="hero-demo">
          <h2 class="hero-demo-title">Interactive Peeling Demo</h2>
          <p class="muted hero-demo-caption">
            Drag across the image to compare the original canopy view vs. the peeled ground-only rendering.
          </p>
          <div class="comparison-controls">
            <div class="comparison-tabs" id="comparison-tabs" role="tablist" aria-label="Example selector"></div>
          </div>
          <div class="comparison-card comparison-card--hero" id="comparison-card">
            <div class="comparison-header">
              <h3 id="comparison-title">Example 1 â€” AOS Dataset</h3>
              <p class="muted" id="comparison-caption"></p>
            </div>
            <div class="comparison-frame" id="comparison-frame">
              <div class="comparison-placeholder" id="comparison-placeholder"></div>
              <div class="comparison-image comparison-image--after" aria-hidden="true">
                <img
                  id="comparison-after"
                  alt="After: peeled ground-only rendering"
                  loading="eager"
                  fetchpriority="high"
                />
              </div>
              <div class="comparison-image comparison-image--before" aria-hidden="true">
                <img
                  id="comparison-before"
                  alt="Before: original canopy view"
                  loading="eager"
                  fetchpriority="high"
                />
              </div>
              <div class="comparison-label comparison-label--before">Before</div>
              <div class="comparison-label comparison-label--after">After</div>
            </div>
            <div class="comparison-slider" aria-label="Reveal slider">
              <input
                id="comparison-slider"
                type="range"
                min="0"
                max="100"
                value="0"
                aria-label="Reveal before image"
              />
            </div>
          </div>
        </div>
      </div>
    </header>

    <main>
      <section class="section" id="pipeline">
        <h2>Method Overview</h2>
        <p>
          Our pipeline starts from high-overlap RGB captures, reconstructs a neural 3D scene, and then applies
          canopy-removal filtering to produce ground-focused renderings for downstream analysis.
        </p>
        <div class="pipeline-image-wrap">
          <img
            class="pipeline-image"
            src="assets/images/pipeline_overview_placeholder.png"
            alt="Pipeline overview placeholder diagram"
            loading="lazy"
          />
        </div>
      </section>

      <section class="section" id="abstract">
        <h2>Abstract</h2>
        <p id="abstract-text"></p>
      </section>

      <section class="section" id="contributions">
        <h2>Key Contributions</h2>
        <ul id="contributions-list"></ul>
      </section>

      <section class="section" id="capture">
        <h2>Capture Guidelines</h2>
        <ul class="icon-list" id="capture-guidelines"></ul>
      </section>

      <section class="section" id="results">
        <h2>Results</h2>
        <div class="results" id="results-list"></div>
        <div class="results-extension" aria-label="Perceptual recovery under heavy occlusion">
          <h3>Perceptual Recovery Under Heavy Occlusion</h3>
          <p>
            In a synthetic dense-canopy scene with ground-truth available, our volumetric NeRF-based reconstruction
            achieves lower LPIPS than vanilla 3DGS (0.56 vs. 0.68), indicating better perceptual recovery of hidden
            ground structure under severe canopy occlusion.
          </p>
          <div class="results-figure-grid" role="group" aria-label="Four-panel qualitative comparison">
            <figure class="results-comparison-figure">
              <img
                src="assets/img/comparisons/heavy-occlusion-comparison.png"
                alt="Four-panel comparison: GT with canopy, GT without canopy, vanilla 3DGS, and our method under heavy occlusion"
                loading="lazy"
              />
            </figure>
          </div>
          <p class="muted results-figure-caption">
            Under heavy canopy occlusion, our method preserves more perceptual ground structure than vanilla 3DGS.
          </p>
        </div>
      </section>

      <section class="section" id="media">
        <h2>Downstream App Examples</h2>
        <div class="media-grid" id="media-grid"></div>
      </section>

      <section class="section" id="citation">
        <div class="citation-header">
          <h2>Citation</h2>
          <button class="icon-button" id="copy-bibtex" type="button" aria-label="Copy citation" title="Copy citation">
            <svg viewBox="0 0 24 24" aria-hidden="true" focusable="false">
              <path
                d="M16 1H4a2 2 0 0 0-2 2v14h2V3h12zM19 5H8a2 2 0 0 0-2 2v14a2 2 0 0 0 2 2h11a2 2 0 0 0 2-2V7a2 2 0 0 0-2-2m0 16H8V7h11z"
              ></path>
            </svg>
          </button>
        </div>
        <pre><code id="bibtex"></code></pre>
      </section>

      <section class="section" id="contact">
        <h2>Contact</h2>
        <p>
          <a id="contact-email" href="mailto:forestvision.lab@gmail.com">forestvision.lab@gmail.com</a>
        </p>
        <p class="muted" id="contact-note"></p>
      </section>
    </main>

    <footer class="footer">
      <p>&copy; <span id="year"></span> Forest Vision Lab</p>
    </footer>

    <script src="assets/js/main.js" defer></script>
  </body>
</html>
